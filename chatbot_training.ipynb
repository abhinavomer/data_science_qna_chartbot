{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec1da4c-7afa-4d77-8b4e-77fc3a11c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"test.csv\",encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833b14ca-ee4b-41b1-8083-03e35231771d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qusetions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Data Science?</td>\n",
       "      <td>Data Science is a field of computer science th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How is Python Useful?</td>\n",
       "      <td>Python is widely recognized as an exceptionall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Supervised Learning?</td>\n",
       "      <td>Supervised learning is a machine learning appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is Unsupervised Learning?</td>\n",
       "      <td>Unsupervised learning is a machine learning ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What do you understand about Linear Regression?</td>\n",
       "      <td>Linear regression helps in understanding the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What do you understand by logistic regression?</td>\n",
       "      <td>Logistic regression is a classification algori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is dimensionality reduction?</td>\n",
       "      <td>Dimensionality reduction is the process of con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is a confusion matrix?</td>\n",
       "      <td>The confusion matrix is a table that is used t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Qusetions  \\\n",
       "0                            What is Data Science?   \n",
       "1                            How is Python Useful?   \n",
       "2                     What is Supervised Learning?   \n",
       "3                   What is Unsupervised Learning?   \n",
       "4  What do you understand about Linear Regression?   \n",
       "5   What do you understand by logistic regression?   \n",
       "6                What is dimensionality reduction?   \n",
       "7                      What is a confusion matrix?   \n",
       "\n",
       "                                             Answers  \n",
       "0  Data Science is a field of computer science th...  \n",
       "1  Python is widely recognized as an exceptionall...  \n",
       "2  Supervised learning is a machine learning appr...  \n",
       "3  Unsupervised learning is a machine learning ap...  \n",
       "4  Linear regression helps in understanding the l...  \n",
       "5  Logistic regression is a classification algori...  \n",
       "6  Dimensionality reduction is the process of con...  \n",
       "7  The confusion matrix is a table that is used t...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da03fe4e-3d31-4724-b30e-8651ddfec90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_list=df['Qusetions'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9294983f-3516-42ac-b23e-6ed5c15ef86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_list=df['Answers'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec8eef9e-62fa-4e4f-9be7-a5a17dbe3cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abhin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abhin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abhin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "231d3622-84a2-42dd-8b97-0ecccd38d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82f7f0b6-39c1-468c-93be-557c8f2e50e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove non-alphanumeric characters\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in lemmatized_tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "def preprocess_with_stopwords(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove non-alphanumeric characters\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in lemmatized_tokens]\n",
    "    return ' '.join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a038f66-ddfb-4eee-a96a-97c463d57cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=nltk.word_tokenize)\n",
    "X = vectorizer.fit_transform([preprocess(q) for q in questions_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38ee1e9c-69e5-4bc6-9a6b-1a26846e4c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_text: who is m dhoni\n",
      "similarities: [[0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "max_similarity: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I can't answer this question.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=nltk.word_tokenize)\n",
    "X = vectorizer.fit_transform([preprocess(q) for q in questions_list])\n",
    "\n",
    "def get_response(text):\n",
    "    processed_text = preprocess_with_stopwords(text)\n",
    "    print(\"processed_text:\", processed_text)\n",
    "    vectorized_text = vectorizer.transform([processed_text])\n",
    "    similarities = cosine_similarity(vectorized_text, X)\n",
    "    print(\"similarities:\", similarities)\n",
    "    max_similarity = np.max(similarities)\n",
    "    print(\"max_similarity:\", max_similarity)\n",
    "    if max_similarity > 0.6:\n",
    "        high_similarity_questions = [q for q, s in zip(questions_list, similarities[0]) if s > 0.6]\n",
    "        print(\"high_similarity_questions:\", high_similarity_questions)\n",
    "\n",
    "        target_answers = []\n",
    "        for q in high_similarity_questions:\n",
    "            q_index = questions_list.index(q)\n",
    "            target_answers.append(answers_list[q_index])\n",
    "        print(target_answers)\n",
    "\n",
    "        Z = vectorizer.fit_transform([preprocess_with_stopwords(q) for q in high_similarity_questions])\n",
    "        processed_text_with_stopwords = preprocess_with_stopwords(text)\n",
    "        print(\"processed_text_with_stopwords:\", processed_text_with_stopwords)\n",
    "        vectorized_text_with_stopwords = vectorizer.transform([processed_text_with_stopwords])\n",
    "        final_similarities = cosine_similarity(vectorized_text_with_stopwords, Z)\n",
    "        closest = np.argmax(final_similarities)\n",
    "        return target_answers[closest]\n",
    "    else:\n",
    "        return \"I can't answer this question.\"\n",
    "\n",
    "get_response('Who is ms dhoni?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "504f71e7-9d47-40f4-9107-1167fb269bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_text: what is data scienc\n",
      "similarities: [[1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "max_similarity: 1.0000000000000002\n",
      "high_similarity_questions: ['What is Data Science?']\n",
      "['Data Science is a field of computer science that explicitly deals with turning data into information and extracting meaningful insights from it. The reason why Data Science is so popular is that the kind of insights it allows us to draw from the available data has led to some major innovations in several products and companies. Using these insights, we are able to determine the taste of a particular customer, the likelihood of a product succeeding in a particular market, etc.']\n",
      "processed_text_with_stopwords: what is data scienc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Data Science is a field of computer science that explicitly deals with turning data into information and extracting meaningful insights from it. The reason why Data Science is so popular is that the kind of insights it allows us to draw from the available data has led to some major innovations in several products and companies. Using these insights, we are able to determine the taste of a particular customer, the likelihood of a product succeeding in a particular market, etc.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=nltk.word_tokenize)\n",
    "X = vectorizer.fit_transform([preprocess(q) for q in questions_list])\n",
    "\n",
    "def get_response(text):\n",
    "    processed_text = preprocess_with_stopwords(text)\n",
    "    print(\"processed_text:\", processed_text)\n",
    "    vectorized_text = vectorizer.transform([processed_text])\n",
    "    similarities = cosine_similarity(vectorized_text, X)\n",
    "    print(\"similarities:\", similarities)\n",
    "    max_similarity = np.max(similarities)\n",
    "    print(\"max_similarity:\", max_similarity)\n",
    "    if max_similarity > 0.6:\n",
    "        high_similarity_questions = [q for q, s in zip(questions_list, similarities[0]) if s > 0.6]\n",
    "        print(\"high_similarity_questions:\", high_similarity_questions)\n",
    "\n",
    "        target_answers = []\n",
    "        for q in high_similarity_questions:\n",
    "            q_index = questions_list.index(q)\n",
    "            target_answers.append(answers_list[q_index])\n",
    "        print(target_answers)\n",
    "\n",
    "        Z = vectorizer.fit_transform([preprocess_with_stopwords(q) for q in high_similarity_questions])\n",
    "        processed_text_with_stopwords = preprocess_with_stopwords(text)\n",
    "        print(\"processed_text_with_stopwords:\", processed_text_with_stopwords)\n",
    "        vectorized_text_with_stopwords = vectorizer.transform([processed_text_with_stopwords])\n",
    "        final_similarities = cosine_similarity(vectorized_text_with_stopwords, Z)\n",
    "        closest = np.argmax(final_similarities)\n",
    "        return target_answers[closest]\n",
    "    else:\n",
    "        return \"I can't answer this question.\"\n",
    "\n",
    "get_response('what is data science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b014f-5c7d-49f5-b094-b1260e935c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae56d95a-12d0-46c7-9747-5298ddbce6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
